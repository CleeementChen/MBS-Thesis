{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "MxxGbTg9j2ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxxGbTg9j2ed",
        "outputId": "45351905-2a03-415c-ffd3-3395d9def647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3.1+cu121\n",
            "12.1\n"
          ]
        }
      ],
      "source": [
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import torch; print(torch.version.cuda)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "szD5a-_wj3Rx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szD5a-_wj3Rx",
        "outputId": "0b75b186-68b3-40a4-cb6a-dc58f5c59522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.9/10.9 MB 110.8 MB/s eta 0:00:00\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt23cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 54.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt23cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_cluster-1.6.3%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 38.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.26.4)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt23cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt23cu121-cp310-cp310-linux_x86_64.whl (947 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 947.1/947.1 kB 15.8 MB/s eta 0:00:00\n",
            "Installing collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2+pt23cu121\n"
          ]
        }
      ],
      "source": [
        "# version should match with torch and cuda\n",
        "%%bash\n",
        "pip install torch-scatter -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "pip install torch-sparse -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "pip install torch-cluster -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.3.0+cu121.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "SEqNnZQQkHE0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEqNnZQQkHE0",
        "outputId": "3ba46d49-1ead-46a2-b88a-104c0635e411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric==2.2.0\n",
            "  Downloading torch_geometric-2.2.0.tar.gz (564 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/565.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m532.5/565.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.2.0) (4.66.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.2.0) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.2.0) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.2.0) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.2.0) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.2.0) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.2.0) (1.3.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.2.0) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric==2.2.0) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.2.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.2.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.2.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric==2.2.0) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.2.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.2.0) (3.5.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.2.0-py3-none-any.whl size=773275 sha256=c667f697677c944849f6ac69e50ab96e83b898bf50a616e6194f9d6e2783986a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/e4/83/5e964867e23f8a61cb8c5d5b9477617b710e96e6ebf1844562\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.2.0\n",
            "Collecting torch_geometric_temporal\n",
            "  Downloading torch_geometric_temporal-0.54.0.tar.gz (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal) (4.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal) (2.3.1+cu121)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal) (3.0.11)\n",
            "Collecting pandas<=1.3.5 (from torch_geometric_temporal)\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal) (0.6.18+pt23cu121)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal) (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal) (2.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal) (1.26.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal) (1.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch_geometric_temporal) (3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->torch_geometric_temporal) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->torch_geometric_temporal) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->torch_geometric_temporal)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->torch_geometric_temporal)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->torch_geometric_temporal)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->torch_geometric_temporal)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->torch_geometric_temporal)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->torch_geometric_temporal)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->torch_geometric_temporal)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->torch_geometric_temporal)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->torch_geometric_temporal)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->torch_geometric_temporal)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->torch_geometric_temporal)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torch_geometric_temporal) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->torch_geometric_temporal)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch_geometric_temporal) (4.66.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch_geometric_temporal) (1.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch_geometric_temporal) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch_geometric_temporal) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch_geometric_temporal) (1.3.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch_geometric_temporal) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch_geometric_temporal) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch_geometric_temporal) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch_geometric_temporal) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch_geometric_temporal) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch_geometric_temporal) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->torch_geometric_temporal) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->torch_geometric_temporal) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torch_geometric_temporal) (1.3.0)\n",
            "Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Building wheels for collected packages: torch_geometric_temporal\n",
            "  Building wheel for torch_geometric_temporal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric_temporal: filename=torch_geometric_temporal-0.54.0-py3-none-any.whl size=86712 sha256=59d51e01445a093ab04ad0eef300060df342bffc88b3098abbb09d83f801a3ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/9b/b6/e15256e053f0cb49b1084a67a709db909d418386a231f0722c\n",
            "Successfully built torch_geometric_temporal\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch_geometric_temporal\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "arviz 0.18.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "bigframes 1.13.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.3.5 which is incompatible.\n",
            "geopandas 0.14.4 requires pandas>=1.4.0, but you have pandas 1.3.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.3.5 which is incompatible.\n",
            "plotnine 0.12.4 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "statsmodels 0.14.2 requires pandas!=2.1.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\n",
            "xarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 pandas-1.3.5 torch_geometric_temporal-0.54.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric==2.2.0\n",
        "!pip install torch_geometric_temporal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1aqqi8SXkJ_c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aqqi8SXkJ_c",
        "outputId": "f0752eee-5893-400e-d8e3-236de0c7a240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "64db5f01-1c67-44a0-bce6-75fbe4da59a5",
      "metadata": {
        "id": "64db5f01-1c67-44a0-bce6-75fbe4da59a5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import os\n",
        "import copy\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch_geometric_temporal.signal import temporal_signal_split\n",
        "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
        "from torch_geometric_temporal.nn.recurrent import A3TGCN2\n",
        "from torch_geometric_temporal.nn.attention import ASTGCN   # For information about the architecture check the source code\n",
        "\n",
        "# GPU support\n",
        "DEVICE = torch.device('cuda') # cuda 有GPU記得加上\n",
        "shuffle=True\n",
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "08c5cae7-a799-48d6-85a5-18322903d3dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08c5cae7-a799-48d6-85a5-18322903d3dc",
        "outputId": "64feb728-2a1f-48c8-c599-890e9801477b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset type:  <class 'torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal'>\n",
            "Number of samples / sequences:  1940\n",
            "First sample: Data(x=[5650, 1, 1], edge_index=[2, 47624], edge_attr=[47624], y=[5650, 1])\n"
          ]
        }
      ],
      "source": [
        "# 從文件加載數據集的組件\n",
        "data = torch.load('/content/drive/MyDrive/Dissertation/DissertationData/static_graph_temporal_signal.pt')\n",
        "\n",
        "edge_index = data['edge_index']\n",
        "edge_attr = data['edge_attr']\n",
        "features_list = data['features']\n",
        "targets_list = data['targets']\n",
        "\n",
        "# 建 StaticGraphTemporalSignal 數據集\n",
        "dataset = StaticGraphTemporalSignal(\n",
        "    edge_index=edge_index,\n",
        "    edge_weight=edge_attr,\n",
        "    features=features_list,\n",
        "    targets=targets_list\n",
        ")\n",
        "\n",
        "# 打印數據集類型\n",
        "print(\"Dataset type: \", type(dataset))\n",
        "\n",
        "# 計算樣本數量（序列數量）\n",
        "num_samples = sum(1 for _ in dataset)\n",
        "print(\"Number of samples / sequences: \", num_samples)\n",
        "\n",
        "# 顯示第一個樣本的內容\n",
        "first_sample = next(iter(dataset))\n",
        "print(\"First sample:\", first_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00173e83-58fc-4b57-903d-b8b48c748d1c",
      "metadata": {
        "id": "00173e83-58fc-4b57-903d-b8b48c748d1c"
      },
      "source": [
        "x=[5650, 1, 1]:\n",
        "\n",
        "x 是特徵張量，形狀為 [num_nodes, num_features, timesteps]。這裡 num_nodes 是 5650，num_features 是 1，timesteps 是 1。這表示每個節點有一個特徵，且時間步長為 1（這與你的設置不完全一致，可能需要檢查設定）。\n",
        "edge_index=[2, 47624]:\n",
        "\n",
        "edge_index 是邊的索引，形狀為 [2, num_edges]，這裡 num_edges 是 47624，表示圖中的邊。\n",
        "edge_attr=[47624]:\n",
        "\n",
        "edge_attr 是邊的權重或相似度，形狀為 [num_edges]，這裡 num_edges 是 47624，與 edge_index 的邊數量一致。\n",
        "y=[5650, 1]:\n",
        "\n",
        "y 是目標張量，形狀為 [num_nodes, timesteps]，這裡 num_nodes 是 5650，timesteps 是 1。這表示每個節點在這個時間步長上的標籤值。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "107f149f-33f2-41f7-bb59-9045685d16f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "107f149f-33f2-41f7-bb59-9045685d16f8",
        "outputId": "af5fce5a-2d57-4628-fdfd-1522ce712598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of train buckets:  1552\n",
            "Number of test buckets:  388\n"
          ]
        }
      ],
      "source": [
        "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
        "\n",
        "train_count = sum(1 for _ in train_dataset)\n",
        "test_count = sum(1 for _ in test_dataset)\n",
        "\n",
        "print(\"Number of train buckets: \", train_count)\n",
        "print(\"Number of test buckets: \", test_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "036fd2a8-c190-4909-a3d4-4a4c94edd0d4",
      "metadata": {
        "id": "036fd2a8-c190-4909-a3d4-4a4c94edd0d4"
      },
      "source": [
        "# ***Creating DataLoaders***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "346f7247-32be-460c-8af2-65c14cf6ed28",
      "metadata": {
        "id": "346f7247-32be-460c-8af2-65c14cf6ed28"
      },
      "outputs": [],
      "source": [
        "# 準備訓練集和測試集的數據\n",
        "train_input = np.array(train_dataset.features)  # (num_samples, num_nodes, num_features, num_timesteps)\n",
        "train_target = np.array(train_dataset.targets)  # (num_samples, num_nodes, num_timesteps)\n",
        "test_input = np.array(test_dataset.features)    # (num_samples, num_nodes, num_features, num_timesteps)\n",
        "test_target = np.array(test_dataset.targets)    # (num_samples, num_nodes, num_timesteps)\n",
        "\n",
        "# 將數據轉換為Tensor\n",
        "train_x_tensor = torch.from_numpy(train_input).type(torch.FloatTensor).to(DEVICE)\n",
        "train_target_tensor = torch.from_numpy(train_target).type(torch.FloatTensor).to(DEVICE)\n",
        "test_x_tensor = torch.from_numpy(test_input).type(torch.FloatTensor).to(DEVICE)\n",
        "test_target_tensor = torch.from_numpy(test_target).type(torch.FloatTensor).to(DEVICE)\n",
        "\n",
        "# 將訓練數據打包為TensorDataset\n",
        "train_dataset_new = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "46eec42d-d2ac-4752-9a41-a16f5483c60b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46eec42d-d2ac-4752-9a41-a16f5483c60b",
        "outputId": "0a54c44f-2dd9-45b8-e388-d04a74676a95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Set: 1242\n",
            "Validation Set: 310\n",
            "Testing Set: 388\n"
          ]
        }
      ],
      "source": [
        "validation_split = 0.2  # 設定驗證集比例\n",
        "\n",
        "# 計算訓練集和驗證集的大小\n",
        "val_size = int(len(train_dataset_new) * validation_split)\n",
        "train_size = len(train_dataset_new) - val_size\n",
        "\n",
        "# 隨機劃分訓練集和驗證集\n",
        "train_dataset_final, val_dataset = torch.utils.data.random_split(train_dataset_new, [train_size, val_size])\n",
        "\n",
        "# 創建 DataLoader\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset_final, batch_size=batch_size, shuffle=shuffle, drop_last=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle, drop_last=True)\n",
        "\n",
        "# 同樣為測試集創建 DataLoader\n",
        "test_dataset_new = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset_new, batch_size=batch_size, shuffle=shuffle, drop_last=True)\n",
        "\n",
        "# 打印劃分後的數據集大小\n",
        "print(f\"Training Set: {len(train_loader.dataset)}\")\n",
        "print(f\"Validation Set: {len(val_loader.dataset)}\")\n",
        "print(f\"Testing Set: {len(test_loader.dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d64e358-fa1e-4b18-9976-5f4aff143b49",
      "metadata": {
        "id": "7d64e358-fa1e-4b18-9976-5f4aff143b49"
      },
      "source": [
        "# ***Model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8933399d-9807-4532-a976-99a2176ddaf6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8933399d-9807-4532-a976-99a2176ddaf6",
        "outputId": "3119826e-115b-4d37-ac02-45e7d406bf6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ASTGCN(\n",
            "  (_blocklist): ModuleList(\n",
            "    (0): ASTGCNBlock(\n",
            "      (_temporal_attention): TemporalAttention()\n",
            "      (_spatial_attention): SpatialAttention()\n",
            "      (_chebconv_attention): ChebConvAttention(1, 64, K=3, normalization=None)\n",
            "      (_time_convolution): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "      (_residual_convolution): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (1): ASTGCNBlock(\n",
            "      (_temporal_attention): TemporalAttention()\n",
            "      (_spatial_attention): SpatialAttention()\n",
            "      (_chebconv_attention): ChebConvAttention(64, 64, K=3, normalization=None)\n",
            "      (_time_convolution): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "      (_residual_convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (_final_conv): Conv2d(1, 1, kernel_size=(1, 64), stride=(1, 1))\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "nb_block = 2\n",
        "in_channels = 1\n",
        "K = 3\n",
        "nb_chev_filter = 64\n",
        "nb_time_filter = 64\n",
        "time_strides = 1  # 我的時間步數\n",
        "num_for_predict = 1  # 我的時間步數\n",
        "len_input = 1  # 我的時間步數\n",
        "num_of_vertices = 5650  # 節點數\n",
        "\n",
        "# Initialize ASTGCN model\n",
        "model = ASTGCN(nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, num_for_predict, len_input, num_of_vertices).to(DEVICE)\n",
        "\n",
        "print(model)  # Print the model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d435ee6e-86c8-4758-b54a-8f5a34569078",
      "metadata": {
        "id": "d435ee6e-86c8-4758-b54a-8f5a34569078"
      },
      "outputs": [],
      "source": [
        "# 定義損失函數和優化器\n",
        "criterion = nn.MSELoss().to(DEVICE)  # 使用均方誤差作為損失函數\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 使用 Adam 優化器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6e75d034-0ee6-4838-a406-1502b9cfee11",
      "metadata": {
        "id": "6e75d034-0ee6-4838-a406-1502b9cfee11"
      },
      "outputs": [],
      "source": [
        "# 定義早停和最佳模型保存的變數\n",
        "min_vali_loss = float('inf')  # 初始化最小驗證損失為無窮大\n",
        "wait = 0  # 用於早停計數\n",
        "best_epoch = 0  # 儲存最佳 epoch\n",
        "model_path = \"/content/drive/MyDrive/Dissertation/DissertationData/best_astgcn_model.params\"  # 儲存最佳模型的路徑\n",
        "early_stop = 5  # 早停的耐心次數\n",
        "masked_flag = 1  # 是否使用遮罩\n",
        "missing_value = 0  # 缺失值的處理方式\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "945d6f1d-b8ef-4c68-8037-e2188053e41e",
      "metadata": {
        "id": "945d6f1d-b8ef-4c68-8037-e2188053e41e"
      },
      "outputs": [],
      "source": [
        "def compute_val_loss_mstgcn(model, val_loader, criterion, masked_flag, missing_value, epoch, edge_index):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_data in val_loader:\n",
        "            encoder_inputs, labels = batch_data\n",
        "            y_hat = model(encoder_inputs, edge_index)\n",
        "\n",
        "            if masked_flag:\n",
        "                mask = (labels != missing_value).float()\n",
        "                loss = (criterion(y_hat, labels) * mask).mean()\n",
        "            else:\n",
        "                loss = criterion(y_hat, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    return val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a3RgkemhTN2s",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a3RgkemhTN2s",
        "outputId": "9a4d431d-85cf-412f-b096-adeb7b40fa1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training for epoch 1...\n",
            "Epoch 1, Step 10, Training Loss: 3.0145\n",
            "Epoch 1, Step 20, Training Loss: 3.4337\n",
            "Epoch 1, Step 30, Training Loss: 2.9517\n",
            "Epoch 1, Step 30, Performing validation...\n",
            "Epoch 1, Step 30, Validation Loss: 0.7356\n",
            "Best epoch so far is 1, Validation Loss: 0.7356. Model saved.\n",
            "Epoch 1, Step 40, Training Loss: 2.8475\n",
            "Epoch 1, Step 50, Training Loss: 3.6135\n",
            "Epoch 1, Step 60, Training Loss: 3.0607\n",
            "Epoch 1, Step 60, Performing validation...\n",
            "Epoch 1, Step 60, Validation Loss: 0.7353\n",
            "Best epoch so far is 1, Validation Loss: 0.7353. Model saved.\n",
            "Epoch 1, Step 70, Training Loss: 3.1288\n",
            "Epoch 1, Step 80, Training Loss: 3.5853\n",
            "Epoch 1, Step 90, Training Loss: 2.9655\n",
            "Epoch 1, Step 90, Performing validation...\n",
            "Epoch 1, Step 90, Validation Loss: 0.7340\n",
            "Best epoch so far is 1, Validation Loss: 0.7340. Model saved.\n",
            "Epoch 1, Step 100, Training Loss: 3.6715\n",
            "Epoch 1, Step 110, Training Loss: 4.0324\n",
            "Epoch 1, Step 120, Training Loss: 3.0851\n",
            "Epoch 1, Step 120, Performing validation...\n",
            "Epoch 1, Step 120, Validation Loss: 0.7425\n",
            "Epoch 1, Step 130, Training Loss: 3.7461\n",
            "Epoch 1, Step 140, Training Loss: 3.4146\n",
            "Epoch 1, Step 150, Training Loss: 3.3829\n",
            "Epoch 1, Step 150, Performing validation...\n",
            "Epoch 1, Step 150, Validation Loss: 0.7288\n",
            "Best epoch so far is 1, Validation Loss: 0.7288. Model saved.\n",
            "Epoch 1 Training RMSE: 1.8200\n",
            "Epoch 1 Validation Loss: 0.7288\n",
            "Starting training for epoch 2...\n",
            "Epoch 2, Step 10, Training Loss: 3.4118\n",
            "Epoch 2, Step 20, Training Loss: 3.0077\n",
            "Epoch 2, Step 30, Training Loss: 3.0887\n",
            "Epoch 2, Step 30, Performing validation...\n",
            "Epoch 2, Step 30, Validation Loss: 0.7269\n",
            "Best epoch so far is 2, Validation Loss: 0.7269. Model saved.\n",
            "Epoch 2, Step 40, Training Loss: 3.9776\n",
            "Epoch 2, Step 50, Training Loss: 3.3634\n",
            "Epoch 2, Step 60, Training Loss: 2.8174\n",
            "Epoch 2, Step 60, Performing validation...\n",
            "Epoch 2, Step 60, Validation Loss: 0.7357\n",
            "Epoch 2, Step 70, Training Loss: 2.6102\n",
            "Epoch 2, Step 80, Training Loss: 4.2383\n",
            "Epoch 2, Step 90, Training Loss: 2.7491\n",
            "Epoch 2, Step 90, Performing validation...\n",
            "Epoch 2, Step 90, Validation Loss: 0.7379\n",
            "Epoch 2, Step 100, Training Loss: 3.6673\n",
            "Epoch 2, Step 110, Training Loss: 3.6167\n",
            "Epoch 2, Step 120, Training Loss: 2.5758\n",
            "Epoch 2, Step 120, Performing validation...\n",
            "Epoch 2, Step 120, Validation Loss: 0.7277\n",
            "Epoch 2, Step 130, Training Loss: 3.2550\n",
            "Epoch 2, Step 140, Training Loss: 2.6485\n",
            "Epoch 2, Step 150, Training Loss: 3.2347\n",
            "Epoch 2, Step 150, Performing validation...\n",
            "Epoch 2, Step 150, Validation Loss: 0.7304\n",
            "Epoch 2 Training RMSE: 1.8177\n",
            "Epoch 2 Validation Loss: 0.7304\n",
            "Starting training for epoch 3...\n",
            "Epoch 3, Step 10, Training Loss: 3.2240\n",
            "Epoch 3, Step 20, Training Loss: 3.6935\n",
            "Epoch 3, Step 30, Training Loss: 2.5959\n",
            "Epoch 3, Step 30, Performing validation...\n",
            "Epoch 3, Step 30, Validation Loss: 0.7333\n",
            "Early stopping at epoch 3.\n",
            "Epoch 3 Training RMSE: 1.8166\n",
            "Epoch 3 Validation Loss: 0.7333\n",
            "Starting training for epoch 4...\n",
            "Epoch 4, Step 10, Training Loss: 3.5288\n",
            "Epoch 4, Step 20, Training Loss: 3.7750\n",
            "Epoch 4, Step 30, Training Loss: 2.5860\n",
            "Epoch 4, Step 30, Performing validation...\n",
            "Epoch 4, Step 30, Validation Loss: 0.7309\n",
            "Early stopping at epoch 4.\n",
            "Epoch 4 Training RMSE: 1.7561\n",
            "Epoch 4 Validation Loss: 0.7309\n",
            "Starting training for epoch 5...\n",
            "Epoch 5, Step 10, Training Loss: 3.3150\n",
            "Epoch 5, Step 20, Training Loss: 3.0055\n",
            "Epoch 5, Step 30, Training Loss: 3.1924\n",
            "Epoch 5, Step 30, Performing validation...\n",
            "Epoch 5, Step 30, Validation Loss: 0.7307\n",
            "Early stopping at epoch 5.\n",
            "Epoch 5 Training RMSE: 1.8426\n",
            "Epoch 5 Validation Loss: 0.7307\n",
            "Starting training for epoch 6...\n",
            "Epoch 6, Step 10, Training Loss: 3.4653\n",
            "Epoch 6, Step 20, Training Loss: 3.1751\n",
            "Epoch 6, Step 30, Training Loss: 2.7958\n",
            "Epoch 6, Step 30, Performing validation...\n",
            "Epoch 6, Step 30, Validation Loss: 0.7321\n",
            "Early stopping at epoch 6.\n",
            "Epoch 6 Training RMSE: 1.7908\n",
            "Epoch 6 Validation Loss: 0.7321\n",
            "Starting training for epoch 7...\n",
            "Epoch 7, Step 10, Training Loss: 3.3438\n",
            "Epoch 7, Step 20, Training Loss: 2.4045\n",
            "Epoch 7, Step 30, Training Loss: 3.4079\n",
            "Epoch 7, Step 30, Performing validation...\n",
            "Epoch 7, Step 30, Validation Loss: 0.7293\n",
            "Early stopping at epoch 7.\n",
            "Epoch 7 Training RMSE: 1.8368\n",
            "Epoch 7 Validation Loss: 0.7293\n",
            "Starting training for epoch 8...\n",
            "Epoch 8, Step 10, Training Loss: 3.7445\n",
            "Epoch 8, Step 20, Training Loss: 4.0893\n",
            "Epoch 8, Step 30, Training Loss: 2.8220\n",
            "Epoch 8, Step 30, Performing validation...\n",
            "Epoch 8, Step 30, Validation Loss: 0.7345\n",
            "Early stopping at epoch 8.\n",
            "Epoch 8 Training RMSE: 1.8249\n",
            "Epoch 8 Validation Loss: 0.7345\n",
            "Starting training for epoch 9...\n",
            "Epoch 9, Step 10, Training Loss: 4.3452\n",
            "Epoch 9, Step 20, Training Loss: 3.6191\n",
            "Epoch 9, Step 30, Training Loss: 2.7390\n",
            "Epoch 9, Step 30, Performing validation...\n",
            "Epoch 9, Step 30, Validation Loss: 0.7376\n",
            "Early stopping at epoch 9.\n",
            "Epoch 9 Training RMSE: 1.8190\n",
            "Epoch 9 Validation Loss: 0.7376\n",
            "Starting training for epoch 10...\n",
            "Epoch 10, Step 10, Training Loss: 2.2292\n",
            "Epoch 10, Step 20, Training Loss: 3.7248\n",
            "Epoch 10, Step 30, Training Loss: 2.8856\n",
            "Epoch 10, Step 30, Performing validation...\n",
            "Epoch 10, Step 30, Validation Loss: 0.7313\n",
            "Early stopping at epoch 10.\n",
            "Epoch 10 Training RMSE: 1.7846\n",
            "Epoch 10 Validation Loss: 0.7313\n",
            "Starting training for epoch 11...\n",
            "Epoch 11, Step 10, Training Loss: 2.7532\n",
            "Epoch 11, Step 20, Training Loss: 3.0965\n",
            "Epoch 11, Step 30, Training Loss: 3.1447\n",
            "Epoch 11, Step 30, Performing validation...\n",
            "Epoch 11, Step 30, Validation Loss: 0.7357\n",
            "Early stopping at epoch 11.\n",
            "Epoch 11 Training RMSE: 1.8313\n",
            "Epoch 11 Validation Loss: 0.7357\n",
            "Starting training for epoch 12...\n",
            "Epoch 12, Step 10, Training Loss: 3.3791\n",
            "Epoch 12, Step 20, Training Loss: 2.9429\n",
            "Epoch 12, Step 30, Training Loss: 2.8840\n",
            "Epoch 12, Step 30, Performing validation...\n",
            "Epoch 12, Step 30, Validation Loss: 0.7309\n",
            "Early stopping at epoch 12.\n",
            "Epoch 12 Training RMSE: 1.8127\n",
            "Epoch 12 Validation Loss: 0.7309\n",
            "Starting training for epoch 13...\n",
            "Epoch 13, Step 10, Training Loss: 3.2202\n",
            "Epoch 13, Step 20, Training Loss: 3.2391\n",
            "Epoch 13, Step 30, Training Loss: 3.6774\n",
            "Epoch 13, Step 30, Performing validation...\n",
            "Epoch 13, Step 30, Validation Loss: 0.7350\n",
            "Early stopping at epoch 13.\n",
            "Epoch 13 Training RMSE: 1.7794\n",
            "Epoch 13 Validation Loss: 0.7350\n",
            "Starting training for epoch 14...\n",
            "Epoch 14, Step 10, Training Loss: 3.5385\n",
            "Epoch 14, Step 20, Training Loss: 3.2664\n",
            "Epoch 14, Step 30, Training Loss: 3.2385\n",
            "Epoch 14, Step 30, Performing validation...\n",
            "Epoch 14, Step 30, Validation Loss: 0.7271\n",
            "Early stopping at epoch 14.\n",
            "Epoch 14 Training RMSE: 1.8030\n",
            "Epoch 14 Validation Loss: 0.7271\n",
            "Starting training for epoch 15...\n",
            "Epoch 15, Step 10, Training Loss: 3.4797\n",
            "Epoch 15, Step 20, Training Loss: 4.2195\n",
            "Epoch 15, Step 30, Training Loss: 2.9482\n",
            "Epoch 15, Step 30, Performing validation...\n",
            "Epoch 15, Step 30, Validation Loss: 0.7266\n",
            "Best epoch so far is 15, Validation Loss: 0.7266. Model saved.\n",
            "Epoch 15, Step 40, Training Loss: 2.5891\n",
            "Epoch 15, Step 50, Training Loss: 2.7844\n",
            "Epoch 15, Step 60, Training Loss: 2.6982\n",
            "Epoch 15, Step 60, Performing validation...\n",
            "Epoch 15, Step 60, Validation Loss: 0.7271\n",
            "Epoch 15, Step 70, Training Loss: 3.4691\n",
            "Epoch 15, Step 80, Training Loss: 3.0869\n",
            "Epoch 15, Step 90, Training Loss: 2.7798\n",
            "Epoch 15, Step 90, Performing validation...\n",
            "Epoch 15, Step 90, Validation Loss: 0.7322\n",
            "Epoch 15, Step 100, Training Loss: 3.1093\n",
            "Epoch 15, Step 110, Training Loss: 2.7685\n",
            "Epoch 15, Step 120, Training Loss: 2.9774\n",
            "Epoch 15, Step 120, Performing validation...\n",
            "Epoch 15, Step 120, Validation Loss: 0.7349\n",
            "Epoch 15, Step 130, Training Loss: 3.3172\n",
            "Epoch 15, Step 140, Training Loss: 4.3264\n",
            "Epoch 15, Step 150, Training Loss: 2.9995\n",
            "Epoch 15, Step 150, Performing validation...\n",
            "Epoch 15, Step 150, Validation Loss: 0.7319\n",
            "Epoch 15 Training RMSE: 1.8170\n",
            "Epoch 15 Validation Loss: 0.7319\n",
            "Starting training for epoch 16...\n",
            "Epoch 16, Step 10, Training Loss: 2.9572\n",
            "Epoch 16, Step 20, Training Loss: 2.9334\n",
            "Epoch 16, Step 30, Training Loss: 2.9561\n",
            "Epoch 16, Step 30, Performing validation...\n",
            "Epoch 16, Step 30, Validation Loss: 0.7324\n",
            "Early stopping at epoch 16.\n",
            "Epoch 16 Training RMSE: 1.7732\n",
            "Epoch 16 Validation Loss: 0.7324\n",
            "Starting training for epoch 17...\n",
            "Epoch 17, Step 10, Training Loss: 3.3863\n",
            "Epoch 17, Step 20, Training Loss: 3.5467\n",
            "Epoch 17, Step 30, Training Loss: 3.4965\n",
            "Epoch 17, Step 30, Performing validation...\n",
            "Epoch 17, Step 30, Validation Loss: 0.7290\n",
            "Early stopping at epoch 17.\n",
            "Epoch 17 Training RMSE: 1.8405\n",
            "Epoch 17 Validation Loss: 0.7290\n",
            "Starting training for epoch 18...\n",
            "Epoch 18, Step 10, Training Loss: 2.6910\n",
            "Epoch 18, Step 20, Training Loss: 2.6646\n",
            "Epoch 18, Step 30, Training Loss: 3.4991\n",
            "Epoch 18, Step 30, Performing validation...\n",
            "Epoch 18, Step 30, Validation Loss: 0.7300\n",
            "Early stopping at epoch 18.\n",
            "Epoch 18 Training RMSE: 1.7897\n",
            "Epoch 18 Validation Loss: 0.7300\n",
            "Starting training for epoch 19...\n",
            "Epoch 19, Step 10, Training Loss: 3.3508\n",
            "Epoch 19, Step 20, Training Loss: 3.1697\n",
            "Epoch 19, Step 30, Training Loss: 2.6723\n",
            "Epoch 19, Step 30, Performing validation...\n",
            "Epoch 19, Step 30, Validation Loss: 0.7317\n",
            "Early stopping at epoch 19.\n",
            "Epoch 19 Training RMSE: 1.8036\n",
            "Epoch 19 Validation Loss: 0.7317\n",
            "Starting training for epoch 20...\n",
            "Epoch 20, Step 10, Training Loss: 3.1271\n",
            "Epoch 20, Step 20, Training Loss: 2.8284\n",
            "Epoch 20, Step 30, Training Loss: 3.6135\n",
            "Epoch 20, Step 30, Performing validation...\n",
            "Epoch 20, Step 30, Validation Loss: 0.7339\n",
            "Early stopping at epoch 20.\n",
            "Epoch 20 Training RMSE: 1.8235\n",
            "Epoch 20 Validation Loss: 0.7339\n",
            "Model saved to /content/drive/MyDrive/Dissertation/DissertationData/best_astgcn_model.params\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "ASTGCN(\n",
              "  (_blocklist): ModuleList(\n",
              "    (0): ASTGCNBlock(\n",
              "      (_temporal_attention): TemporalAttention()\n",
              "      (_spatial_attention): SpatialAttention()\n",
              "      (_chebconv_attention): ChebConvAttention(1, 64, K=3, normalization=None)\n",
              "      (_time_convolution): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
              "      (_residual_convolution): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): ASTGCNBlock(\n",
              "      (_temporal_attention): TemporalAttention()\n",
              "      (_spatial_attention): SpatialAttention()\n",
              "      (_chebconv_attention): ChebConvAttention(64, 64, K=3, normalization=None)\n",
              "      (_time_convolution): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
              "      (_residual_convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (_final_conv): Conv2d(1, 1, kernel_size=(1, 64), stride=(1, 1))\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for epoch in range(20):\n",
        "    print(f\"Starting training for epoch {epoch + 1}...\")\n",
        "    model.train()\n",
        "    step = 0\n",
        "    loss_list = []\n",
        "\n",
        "    for batch_data in train_loader:\n",
        "        encoder_inputs, labels = batch_data\n",
        "        encoder_inputs = encoder_inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        edge_index = edge_index.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        y_hat = model(encoder_inputs, edge_index)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(y_hat, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        step += 1\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Epoch {epoch + 1}, Step {step}, Training Loss: {loss.item():.4f}\")\n",
        "\n",
        "        if step % 30 == 0:\n",
        "            print(f\"Epoch {epoch + 1}, Step {step}, Performing validation...\")\n",
        "            vali_loss = compute_val_loss_mstgcn(model, val_loader, criterion, masked_flag, missing_value, epoch, edge_index)\n",
        "            print(f\"Epoch {epoch + 1}, Step {step}, Validation Loss: {vali_loss:.4f}\")\n",
        "\n",
        "            if vali_loss < min_vali_loss:\n",
        "                wait = 0\n",
        "                min_vali_loss = vali_loss\n",
        "                best_epoch = epoch\n",
        "                best_state_dict = copy.deepcopy(model.state_dict())\n",
        "                print(f\"Best epoch so far is {best_epoch + 1}, Validation Loss: {min_vali_loss:.4f}. Model saved.\")\n",
        "            else:\n",
        "                wait += 1\n",
        "                if wait >= early_stop:\n",
        "                    print(f\"Early stopping at epoch {epoch + 1}.\")\n",
        "                    model.load_state_dict(best_state_dict)\n",
        "                    break  # Directly return, stopping training\n",
        "\n",
        "            model.train()\n",
        "\n",
        "    train_rmse = np.sqrt(np.mean(loss_list))\n",
        "    train_losses.append(train_rmse)  # Traing loss for plot\n",
        "    val_losses.append(vali_loss)     # Validation loss for plot\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} Training RMSE: {train_rmse:.4f}\")\n",
        "    print(f\"Epoch {epoch + 1} Validation Loss: {vali_loss:.4f}\")\n",
        "\n",
        "# 保存最佳模型\n",
        "torch.save(best_state_dict, model_path)\n",
        "print(f\"Model saved to {model_path}\")\n",
        "\n",
        "# 收斂圖\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label='Training Loss', marker='o')\n",
        "plt.plot(val_losses, label='Validation Loss', marker='o')\n",
        "plt.title('Training & Validation Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss (RMSE)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 評估部分\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "619b2c8a-4b3d-4e3c-8ab2-db952d4aced5",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "619b2c8a-4b3d-4e3c-8ab2-db952d4aced5",
        "outputId": "f82dcb9a-683b-4c89-b702-01414c0c7134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "開始訓練第 1 個 epoch...\n",
            "Epoch 1, Step 10, 訓練損失: 4.0310\n",
            "Epoch 1, Step 20, 訓練損失: 3.1086\n",
            "Epoch 1, Step 30, 訓練損失: 3.3412\n",
            "Epoch 1, Step 30, 正在進行驗證...\n",
            "Epoch 1, Step 30, 驗證損失: 0.7559\n",
            "目前最佳的 epoch 是 1，驗證損失: 0.7559，保存模型。\n",
            "Epoch 1, Step 40, 訓練損失: 3.2470\n",
            "Epoch 1, Step 50, 訓練損失: 3.0194\n",
            "Epoch 1, Step 60, 訓練損失: 3.2715\n",
            "Epoch 1, Step 60, 正在進行驗證...\n",
            "Epoch 1, Step 60, 驗證損失: 0.7500\n",
            "目前最佳的 epoch 是 1，驗證損失: 0.7500，保存模型。\n",
            "Epoch 1, Step 70, 訓練損失: 3.6542\n",
            "Epoch 1, Step 80, 訓練損失: 3.2631\n",
            "Epoch 1, Step 90, 訓練損失: 2.9790\n",
            "Epoch 1, Step 90, 正在進行驗證...\n",
            "Epoch 1, Step 90, 驗證損失: 0.7531\n",
            "Epoch 1, Step 100, 訓練損失: 3.5443\n",
            "Epoch 1, Step 110, 訓練損失: 2.3445\n",
            "Epoch 1, Step 120, 訓練損失: 3.1259\n",
            "Epoch 1, Step 120, 正在進行驗證...\n",
            "Epoch 1, Step 120, 驗證損失: 0.7337\n",
            "目前最佳的 epoch 是 1，驗證損失: 0.7337，保存模型。\n",
            "Epoch 1, Step 130, 訓練損失: 3.2028\n",
            "Epoch 1, Step 140, 訓練損失: 3.2653\n",
            "Epoch 1, Step 150, 訓練損失: 3.0561\n",
            "Epoch 1, Step 150, 正在進行驗證...\n",
            "Epoch 1, Step 150, 驗證損失: 0.7217\n",
            "目前最佳的 epoch 是 1，驗證損失: 0.7217，保存模型。\n",
            "Epoch 1 訓練 RMSE: 1.8257\n",
            "Epoch 1 驗證損失: 0.7217\n",
            "開始訓練第 2 個 epoch...\n",
            "Epoch 2, Step 10, 訓練損失: 2.9014\n",
            "Epoch 2, Step 20, 訓練損失: 3.6273\n",
            "Epoch 2, Step 30, 訓練損失: 2.7365\n",
            "Epoch 2, Step 30, 正在進行驗證...\n",
            "Epoch 2, Step 30, 驗證損失: 0.7067\n",
            "目前最佳的 epoch 是 2，驗證損失: 0.7067，保存模型。\n",
            "Epoch 2, Step 40, 訓練損失: 2.6026\n",
            "Epoch 2, Step 50, 訓練損失: 3.7112\n",
            "Epoch 2, Step 60, 訓練損失: 3.5328\n",
            "Epoch 2, Step 60, 正在進行驗證...\n",
            "Epoch 2, Step 60, 驗證損失: 0.6970\n",
            "目前最佳的 epoch 是 2，驗證損失: 0.6970，保存模型。\n",
            "Epoch 2, Step 70, 訓練損失: 2.8101\n",
            "Epoch 2, Step 80, 訓練損失: 3.5090\n",
            "Epoch 2, Step 90, 訓練損失: 3.1130\n",
            "Epoch 2, Step 90, 正在進行驗證...\n",
            "Epoch 2, Step 90, 驗證損失: 0.6871\n",
            "目前最佳的 epoch 是 2，驗證損失: 0.6871，保存模型。\n",
            "Epoch 2, Step 100, 訓練損失: 2.7736\n",
            "Epoch 2, Step 110, 訓練損失: 2.4964\n",
            "Epoch 2, Step 120, 訓練損失: 2.7143\n",
            "Epoch 2, Step 120, 正在進行驗證...\n",
            "Epoch 2, Step 120, 驗證損失: 0.6686\n",
            "目前最佳的 epoch 是 2，驗證損失: 0.6686，保存模型。\n",
            "Epoch 2, Step 130, 訓練損失: 2.9267\n",
            "Epoch 2, Step 140, 訓練損失: 2.8035\n",
            "Epoch 2, Step 150, 訓練損失: 2.3859\n",
            "Epoch 2, Step 150, 正在進行驗證...\n",
            "Epoch 2, Step 150, 驗證損失: 0.6610\n",
            "目前最佳的 epoch 是 2，驗證損失: 0.6610，保存模型。\n",
            "Epoch 2 訓練 RMSE: 1.7456\n",
            "Epoch 2 驗證損失: 0.6610\n",
            "開始訓練第 3 個 epoch...\n",
            "Epoch 3, Step 10, 訓練損失: 3.0152\n",
            "Epoch 3, Step 20, 訓練損失: 2.9994\n",
            "Epoch 3, Step 30, 訓練損失: 3.2970\n",
            "Epoch 3, Step 30, 正在進行驗證...\n",
            "Epoch 3, Step 30, 驗證損失: 0.6571\n",
            "目前最佳的 epoch 是 3，驗證損失: 0.6571，保存模型。\n",
            "Epoch 3, Step 40, 訓練損失: 2.7578\n",
            "Epoch 3, Step 50, 訓練損失: 2.5640\n",
            "Epoch 3, Step 60, 訓練損失: 2.3338\n",
            "Epoch 3, Step 60, 正在進行驗證...\n",
            "Epoch 3, Step 60, 驗證損失: 0.6486\n",
            "目前最佳的 epoch 是 3，驗證損失: 0.6486，保存模型。\n",
            "Epoch 3, Step 70, 訓練損失: 2.7984\n",
            "Epoch 3, Step 80, 訓練損失: 3.0203\n",
            "Epoch 3, Step 90, 訓練損失: 3.5852\n",
            "Epoch 3, Step 90, 正在進行驗證...\n",
            "Epoch 3, Step 90, 驗證損失: 0.6410\n",
            "目前最佳的 epoch 是 3，驗證損失: 0.6410，保存模型。\n",
            "Epoch 3, Step 100, 訓練損失: 3.0780\n",
            "Epoch 3, Step 110, 訓練損失: 2.9869\n",
            "Epoch 3, Step 120, 訓練損失: 2.9178\n",
            "Epoch 3, Step 120, 正在進行驗證...\n",
            "Epoch 3, Step 120, 驗證損失: 0.6353\n",
            "目前最佳的 epoch 是 3，驗證損失: 0.6353，保存模型。\n",
            "Epoch 3, Step 130, 訓練損失: 2.4216\n",
            "Epoch 3, Step 140, 訓練損失: 2.6009\n",
            "Epoch 3, Step 150, 訓練損失: 3.3418\n",
            "Epoch 3, Step 150, 正在進行驗證...\n",
            "Epoch 3, Step 150, 驗證損失: 0.6320\n",
            "目前最佳的 epoch 是 3，驗證損失: 0.6320，保存模型。\n",
            "Epoch 3 訓練 RMSE: 1.6883\n",
            "Epoch 3 驗證損失: 0.6320\n",
            "開始訓練第 4 個 epoch...\n",
            "Epoch 4, Step 10, 訓練損失: 3.0532\n",
            "Epoch 4, Step 20, 訓練損失: 3.0912\n",
            "Epoch 4, Step 30, 訓練損失: 2.7473\n",
            "Epoch 4, Step 30, 正在進行驗證...\n",
            "Epoch 4, Step 30, 驗證損失: 0.6403\n",
            "Epoch 4, Step 40, 訓練損失: 3.9361\n",
            "Epoch 4, Step 50, 訓練損失: 2.9553\n",
            "Epoch 4, Step 60, 訓練損失: 2.7890\n",
            "Epoch 4, Step 60, 正在進行驗證...\n",
            "Epoch 4, Step 60, 驗證損失: 0.6318\n",
            "目前最佳的 epoch 是 4，驗證損失: 0.6318，保存模型。\n",
            "Epoch 4, Step 70, 訓練損失: 2.6113\n",
            "Epoch 4, Step 80, 訓練損失: 3.0350\n",
            "Epoch 4, Step 90, 訓練損失: 2.4125\n",
            "Epoch 4, Step 90, 正在進行驗證...\n",
            "Epoch 4, Step 90, 驗證損失: 0.6304\n",
            "目前最佳的 epoch 是 4，驗證損失: 0.6304，保存模型。\n",
            "Epoch 4, Step 100, 訓練損失: 2.2739\n",
            "Epoch 4, Step 110, 訓練損失: 2.7438\n",
            "Epoch 4, Step 120, 訓練損失: 2.4767\n",
            "Epoch 4, Step 120, 正在進行驗證...\n",
            "Epoch 4, Step 120, 驗證損失: 0.6293\n",
            "目前最佳的 epoch 是 4，驗證損失: 0.6293，保存模型。\n",
            "Epoch 4, Step 130, 訓練損失: 2.7922\n",
            "Epoch 4, Step 140, 訓練損失: 2.5222\n",
            "Epoch 4, Step 150, 訓練損失: 2.9721\n",
            "Epoch 4, Step 150, 正在進行驗證...\n",
            "Epoch 4, Step 150, 驗證損失: 0.6157\n",
            "目前最佳的 epoch 是 4，驗證損失: 0.6157，保存模型。\n",
            "Epoch 4 訓練 RMSE: 1.6639\n",
            "Epoch 4 驗證損失: 0.6157\n",
            "開始訓練第 5 個 epoch...\n",
            "Epoch 5, Step 10, 訓練損失: 2.9220\n",
            "Epoch 5, Step 20, 訓練損失: 2.8040\n",
            "Epoch 5, Step 30, 訓練損失: 2.9508\n",
            "Epoch 5, Step 30, 正在進行驗證...\n",
            "Epoch 5, Step 30, 驗證損失: 0.6298\n",
            "Epoch 5, Step 40, 訓練損失: 2.2735\n",
            "Epoch 5, Step 50, 訓練損失: 2.8911\n",
            "Epoch 5, Step 60, 訓練損失: 2.9966\n",
            "Epoch 5, Step 60, 正在進行驗證...\n",
            "Epoch 5, Step 60, 驗證損失: 0.6265\n",
            "Epoch 5, Step 70, 訓練損失: 2.5099\n",
            "Epoch 5, Step 80, 訓練損失: 3.1167\n",
            "Epoch 5, Step 90, 訓練損失: 2.6545\n",
            "Epoch 5, Step 90, 正在進行驗證...\n",
            "Epoch 5, Step 90, 驗證損失: 0.6286\n",
            "Epoch 5, Step 100, 訓練損失: 2.5909\n",
            "Epoch 5, Step 110, 訓練損失: 2.3143\n",
            "Epoch 5, Step 120, 訓練損失: 2.8489\n",
            "Epoch 5, Step 120, 正在進行驗證...\n",
            "Epoch 5, Step 120, 驗證損失: 0.6242\n",
            "Epoch 5, Step 130, 訓練損失: 2.9489\n",
            "Epoch 5, Step 140, 訓練損失: 2.9143\n",
            "Epoch 5, Step 150, 訓練損失: 2.6646\n",
            "Epoch 5, Step 150, 正在進行驗證...\n",
            "Epoch 5, Step 150, 驗證損失: 0.6282\n",
            "Epoch 5 訓練 RMSE: 1.6490\n",
            "Epoch 5 驗證損失: 0.6282\n",
            "開始訓練第 6 個 epoch...\n",
            "Epoch 6, Step 10, 訓練損失: 2.5559\n",
            "Epoch 6, Step 20, 訓練損失: 2.4033\n",
            "Epoch 6, Step 30, 訓練損失: 2.6158\n",
            "Epoch 6, Step 30, 正在進行驗證...\n",
            "Epoch 6, Step 30, 驗證損失: 0.6205\n",
            "Epoch 6, Step 40, 訓練損失: 2.5845\n",
            "Epoch 6, Step 50, 訓練損失: 2.7981\n",
            "Epoch 6, Step 60, 訓練損失: 2.9526\n",
            "Epoch 6, Step 60, 正在進行驗證...\n",
            "Epoch 6, Step 60, 驗證損失: 0.6197\n",
            "Epoch 6, Step 70, 訓練損失: 3.0098\n",
            "Epoch 6, Step 80, 訓練損失: 2.6115\n",
            "Epoch 6, Step 90, 訓練損失: 2.8211\n",
            "Epoch 6, Step 90, 正在進行驗證...\n",
            "Epoch 6, Step 90, 驗證損失: 0.6242\n",
            "Epoch 6, Step 100, 訓練損失: 2.6730\n",
            "Epoch 6, Step 110, 訓練損失: 2.4780\n",
            "Epoch 6, Step 120, 訓練損失: 2.6718\n",
            "Epoch 6, Step 120, 正在進行驗證...\n",
            "Epoch 6, Step 120, 驗證損失: 0.6205\n",
            "Epoch 6, Step 130, 訓練損失: 2.6898\n",
            "Epoch 6, Step 140, 訓練損失: 2.9237\n",
            "Epoch 6, Step 150, 訓練損失: 2.1575\n",
            "Epoch 6, Step 150, 正在進行驗證...\n",
            "Epoch 6, Step 150, 驗證損失: 0.6241\n",
            "在 epoch 6 早停。\n",
            "Epoch 6 訓練 RMSE: 1.6240\n",
            "Epoch 6 驗證損失: 0.6241\n",
            "開始訓練第 7 個 epoch...\n",
            "Epoch 7, Step 10, 訓練損失: 2.8206\n",
            "Epoch 7, Step 20, 訓練損失: 3.4474\n",
            "Epoch 7, Step 30, 訓練損失: 2.9853\n",
            "Epoch 7, Step 30, 正在進行驗證...\n",
            "Epoch 7, Step 30, 驗證損失: 0.6250\n",
            "在 epoch 7 早停。\n",
            "Epoch 7 訓練 RMSE: 1.6672\n",
            "Epoch 7 驗證損失: 0.6250\n",
            "開始訓練第 8 個 epoch...\n",
            "Epoch 8, Step 10, 訓練損失: 2.0605\n",
            "Epoch 8, Step 20, 訓練損失: 2.5897\n",
            "Epoch 8, Step 30, 訓練損失: 2.4973\n",
            "Epoch 8, Step 30, 正在進行驗證...\n",
            "Epoch 8, Step 30, 驗證損失: 0.6380\n",
            "在 epoch 8 早停。\n",
            "Epoch 8 訓練 RMSE: 1.6616\n",
            "Epoch 8 驗證損失: 0.6380\n",
            "開始訓練第 9 個 epoch...\n",
            "Epoch 9, Step 10, 訓練損失: 3.2583\n",
            "Epoch 9, Step 20, 訓練損失: 2.3123\n",
            "Epoch 9, Step 30, 訓練損失: 3.3001\n",
            "Epoch 9, Step 30, 正在進行驗證...\n",
            "Epoch 9, Step 30, 驗證損失: 0.6224\n",
            "在 epoch 9 早停。\n",
            "Epoch 9 訓練 RMSE: 1.6460\n",
            "Epoch 9 驗證損失: 0.6224\n",
            "開始訓練第 10 個 epoch...\n",
            "Epoch 10, Step 10, 訓練損失: 2.5970\n",
            "Epoch 10, Step 20, 訓練損失: 2.8001\n",
            "Epoch 10, Step 30, 訓練損失: 2.3309\n",
            "Epoch 10, Step 30, 正在進行驗證...\n",
            "Epoch 10, Step 30, 驗證損失: 0.6278\n",
            "在 epoch 10 早停。\n",
            "Epoch 10 訓練 RMSE: 1.6519\n",
            "Epoch 10 驗證損失: 0.6278\n",
            "開始訓練第 11 個 epoch...\n",
            "Epoch 11, Step 10, 訓練損失: 2.6376\n",
            "Epoch 11, Step 20, 訓練損失: 2.5834\n",
            "Epoch 11, Step 30, 訓練損失: 3.0587\n",
            "Epoch 11, Step 30, 正在進行驗證...\n",
            "Epoch 11, Step 30, 驗證損失: 0.6308\n",
            "在 epoch 11 早停。\n",
            "Epoch 11 訓練 RMSE: 1.6528\n",
            "Epoch 11 驗證損失: 0.6308\n",
            "開始訓練第 12 個 epoch...\n",
            "Epoch 12, Step 10, 訓練損失: 2.5536\n",
            "Epoch 12, Step 20, 訓練損失: 3.2503\n",
            "Epoch 12, Step 30, 訓練損失: 2.6592\n",
            "Epoch 12, Step 30, 正在進行驗證...\n",
            "Epoch 12, Step 30, 驗證損失: 0.6294\n",
            "在 epoch 12 早停。\n",
            "Epoch 12 訓練 RMSE: 1.6497\n",
            "Epoch 12 驗證損失: 0.6294\n",
            "開始訓練第 13 個 epoch...\n",
            "Epoch 13, Step 10, 訓練損失: 2.3071\n",
            "Epoch 13, Step 20, 訓練損失: 2.8045\n",
            "Epoch 13, Step 30, 訓練損失: 2.6090\n",
            "Epoch 13, Step 30, 正在進行驗證...\n",
            "Epoch 13, Step 30, 驗證損失: 0.6211\n",
            "在 epoch 13 早停。\n",
            "Epoch 13 訓練 RMSE: 1.6289\n",
            "Epoch 13 驗證損失: 0.6211\n",
            "開始訓練第 14 個 epoch...\n",
            "Epoch 14, Step 10, 訓練損失: 2.7139\n",
            "Epoch 14, Step 20, 訓練損失: 2.8049\n",
            "Epoch 14, Step 30, 訓練損失: 2.8050\n",
            "Epoch 14, Step 30, 正在進行驗證...\n",
            "Epoch 14, Step 30, 驗證損失: 0.6259\n",
            "在 epoch 14 早停。\n",
            "Epoch 14 訓練 RMSE: 1.6432\n",
            "Epoch 14 驗證損失: 0.6259\n",
            "開始訓練第 15 個 epoch...\n",
            "Epoch 15, Step 10, 訓練損失: 2.3557\n",
            "Epoch 15, Step 20, 訓練損失: 2.7292\n",
            "Epoch 15, Step 30, 訓練損失: 2.4010\n",
            "Epoch 15, Step 30, 正在進行驗證...\n",
            "Epoch 15, Step 30, 驗證損失: 0.6312\n",
            "在 epoch 15 早停。\n",
            "Epoch 15 訓練 RMSE: 1.6703\n",
            "Epoch 15 驗證損失: 0.6312\n",
            "開始訓練第 16 個 epoch...\n",
            "Epoch 16, Step 10, 訓練損失: 2.8692\n",
            "Epoch 16, Step 20, 訓練損失: 2.2709\n",
            "Epoch 16, Step 30, 訓練損失: 2.8047\n",
            "Epoch 16, Step 30, 正在進行驗證...\n",
            "Epoch 16, Step 30, 驗證損失: 0.6157\n",
            "在 epoch 16 早停。\n",
            "Epoch 16 訓練 RMSE: 1.6262\n",
            "Epoch 16 驗證損失: 0.6157\n",
            "開始訓練第 17 個 epoch...\n",
            "Epoch 17, Step 10, 訓練損失: 2.7934\n",
            "Epoch 17, Step 20, 訓練損失: 2.6732\n",
            "Epoch 17, Step 30, 訓練損失: 2.4100\n",
            "Epoch 17, Step 30, 正在進行驗證...\n",
            "Epoch 17, Step 30, 驗證損失: 0.6247\n",
            "在 epoch 17 早停。\n",
            "Epoch 17 訓練 RMSE: 1.6798\n",
            "Epoch 17 驗證損失: 0.6247\n",
            "開始訓練第 18 個 epoch...\n",
            "Epoch 18, Step 10, 訓練損失: 2.8350\n",
            "Epoch 18, Step 20, 訓練損失: 2.9990\n",
            "Epoch 18, Step 30, 訓練損失: 2.5357\n",
            "Epoch 18, Step 30, 正在進行驗證...\n",
            "Epoch 18, Step 30, 驗證損失: 0.6245\n",
            "在 epoch 18 早停。\n",
            "Epoch 18 訓練 RMSE: 1.6776\n",
            "Epoch 18 驗證損失: 0.6245\n",
            "開始訓練第 19 個 epoch...\n",
            "Epoch 19, Step 10, 訓練損失: 2.5973\n",
            "Epoch 19, Step 20, 訓練損失: 2.9138\n",
            "Epoch 19, Step 30, 訓練損失: 2.0908\n",
            "Epoch 19, Step 30, 正在進行驗證...\n",
            "Epoch 19, Step 30, 驗證損失: 0.6281\n",
            "在 epoch 19 早停。\n",
            "Epoch 19 訓練 RMSE: 1.6326\n",
            "Epoch 19 驗證損失: 0.6281\n",
            "開始訓練第 20 個 epoch...\n",
            "Epoch 20, Step 10, 訓練損失: 2.8255\n",
            "Epoch 20, Step 20, 訓練損失: 2.8496\n",
            "Epoch 20, Step 30, 訓練損失: 2.8265\n",
            "Epoch 20, Step 30, 正在進行驗證...\n",
            "Epoch 20, Step 30, 驗證損失: 0.6238\n",
            "在 epoch 20 早停。\n",
            "Epoch 20 訓練 RMSE: 1.6435\n",
            "Epoch 20 驗證損失: 0.6238\n",
            "模型已保存至 ./best_astgcn_model.params\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ASTGCN(\n",
              "  (_blocklist): ModuleList(\n",
              "    (0): ASTGCNBlock(\n",
              "      (_temporal_attention): TemporalAttention()\n",
              "      (_spatial_attention): SpatialAttention()\n",
              "      (_chebconv_attention): ChebConvAttention(1, 64, K=3, normalization=None)\n",
              "      (_time_convolution): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
              "      (_residual_convolution): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): ASTGCNBlock(\n",
              "      (_temporal_attention): TemporalAttention()\n",
              "      (_spatial_attention): SpatialAttention()\n",
              "      (_chebconv_attention): ChebConvAttention(64, 64, K=3, normalization=None)\n",
              "      (_time_convolution): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
              "      (_residual_convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (_final_conv): Conv2d(1, 1, kernel_size=(1, 64), stride=(1, 1))\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 訓練過程\n",
        "for epoch in range(20):\n",
        "    print(f\"開始訓練第 {epoch + 1} 個 epoch...\")\n",
        "    model.train()\n",
        "    step = 0\n",
        "    loss_list = []\n",
        "\n",
        "    for batch_data in train_loader:\n",
        "        encoder_inputs, labels = batch_data\n",
        "        encoder_inputs = encoder_inputs.to(DEVICE)  # 確保 encoder_inputs 在 GPU 上\n",
        "        labels = labels.to(DEVICE)  # 確保 labels 在 GPU 上\n",
        "        edge_index = edge_index.to(DEVICE)  # 確保 edge_index 在 GPU 上\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 前向傳播：獲取模型預測\n",
        "        y_hat = model(encoder_inputs, edge_index)\n",
        "\n",
        "        # 計算損失\n",
        "        loss = criterion(y_hat, labels)\n",
        "        #print(f\"Step {step + 1}, 計算損失 (loss): {loss.item():.4f}\")  # 打印損失值\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        step += 1\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # 每 10 步打印一次當前訓練情況\n",
        "        if step % 10 == 0:\n",
        "            print(f\"Epoch {epoch + 1}, Step {step}, 訓練損失: {loss.item():.4f}\")\n",
        "\n",
        "        # 每 30 步進行一次驗證\n",
        "        if step % 30 == 0:\n",
        "            print(f\"Epoch {epoch + 1}, Step {step}, 正在進行驗證...\")\n",
        "            vali_loss = compute_val_loss_mstgcn(model, val_loader, criterion, masked_flag, missing_value, epoch, edge_index)\n",
        "            print(f\"Epoch {epoch + 1}, Step {step}, 驗證損失: {vali_loss:.4f}\")\n",
        "\n",
        "            if vali_loss < min_vali_loss:\n",
        "                wait = 0\n",
        "                min_vali_loss = vali_loss\n",
        "                best_epoch = epoch\n",
        "                best_state_dict = copy.deepcopy(model.state_dict())\n",
        "                print(f\"目前最佳的 epoch 是 {best_epoch + 1}，驗證損失: {min_vali_loss:.4f}，保存模型。\")\n",
        "            else:\n",
        "                wait += 1\n",
        "                if wait >= early_stop:\n",
        "                    print(f\"在 epoch {epoch + 1} 早停。\")\n",
        "                    model.load_state_dict(best_state_dict)\n",
        "                    break\n",
        "\n",
        "            model.train()\n",
        "\n",
        "    # 輸出當前 epoch 的訓練和驗證結果\n",
        "    train_rmse = np.sqrt(np.mean(loss_list))\n",
        "    print(f\"Epoch {epoch + 1} 訓練 RMSE: {train_rmse:.4f}\")\n",
        "    print(f\"Epoch {epoch + 1} 驗證損失: {vali_loss:.4f}\")\n",
        "\n",
        "# 保存最佳模型\n",
        "torch.save(best_state_dict, model_path)\n",
        "print(f\"模型已保存至 {model_path}\")\n",
        "\n",
        "# 評估部分\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17b22167-9ac3-4799-8642-d13249945b92",
      "metadata": {
        "id": "17b22167-9ac3-4799-8642-d13249945b92"
      },
      "source": [
        "# ***Evaluate***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a15de3cb-2d3f-46b5-bc43-253c5add8978",
      "metadata": {
        "id": "a15de3cb-2d3f-46b5-bc43-253c5add8978",
        "outputId": "c26e8f50-755f-4f16-8d23-2e346d81fccb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test MSE: 4.1212\n"
          ]
        }
      ],
      "source": [
        "# 測試部分\n",
        "model.eval()  # 切換模型到評估模式\n",
        "test_loss = 0\n",
        "\n",
        "all_outputs = []  # 用於保存所有批次的預測結果\n",
        "all_labels = []  # 用於保存所有批次的真實標籤\n",
        "\n",
        "with torch.no_grad():  # 在測試過程中禁用梯度計算\n",
        "    for batch_data in test_loader:\n",
        "        encoder_inputs, labels = batch_data\n",
        "        encoder_inputs = encoder_inputs.to(DEVICE)  # 將數據移動到 GPU\n",
        "        labels = labels.to(DEVICE)\n",
        "        edge_index = edge_index.to(DEVICE)\n",
        "\n",
        "        # 模型推斷\n",
        "        y_hat = model(encoder_inputs, edge_index)\n",
        "\n",
        "        # 計算損失\n",
        "        if masked_flag:\n",
        "            mask = (labels != missing_value).float()\n",
        "            loss = (criterion(y_hat, labels) * mask).mean()\n",
        "        else:\n",
        "            loss = criterion(y_hat, labels)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # 保存當前批次的預測結果和真實標籤\n",
        "        all_outputs.append(y_hat.cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "# 計算平均測試損失\n",
        "test_loss /= len(test_loader)\n",
        "print(f\"測試損失: {test_loss:.4f}\")\n",
        "\n",
        "# 將所有批次的結果拼接成一個大的張量\n",
        "all_outputs = torch.cat(all_outputs, dim=0)\n",
        "all_labels = torch.cat(all_labels, dim=0)\n",
        "\n",
        "# 可視化部分\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "# 取出一部分樣本進行可視化比較\n",
        "sample_output = all_outputs[:50]  # 取前 50 個樣本的預測\n",
        "sample_labels = all_labels[:50]  # 取前 50 個樣本的真實值\n",
        "\n",
        "# 檢查形狀\n",
        "print(f\"Sample output shape: {sample_output.shape}, Sample labels shape: {sample_labels.shape}\")\n",
        "\n",
        "# 設置圖形的大小和 DPI\n",
        "figure(figsize=(30, 4), dpi=80)\n",
        "\n",
        "# 可視化50個序列的預測值與真實值\n",
        "for i in range(50):\n",
        "    new_i = i * 12\n",
        "    plt.plot(range(0+new_i, 12+new_i), sample_output[i].detach().numpy(), color='red', label='Prediction' if i == 0 else \"\")\n",
        "    plt.plot(range(0+new_i, 12+new_i), sample_labels[i].numpy(), color='blue', label='Truth' if i == 0 else \"\")\n",
        "\n",
        "# 添加圖例以區分預測值和真實值\n",
        "plt.legend()\n",
        "\n",
        "# 顯示圖形\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
